{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6eGvEJ70XZK"
      },
      "source": [
        "#creates a  network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v3D5ykjrzqbI"
      },
      "outputs": [],
      "source": [
        "# Initialize a network\n",
        "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
        "\tnetwork = list()\n",
        "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
        "\tnetwork.append(hidden_layer)\n",
        "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
        "\tnetwork.append(output_layer)\n",
        "\treturn network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92U7L7RH0kBB",
        "outputId": "ec3cd022-de53-40ff-9493-86cc93565099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}, {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}]\n",
            "[{'weights': [0.651592972722763, 0.7887233511355132, 0.0938595867742349]}]\n"
          ]
        }
      ],
      "source": [
        "from random import seed\n",
        "from random import random\n",
        "seed(1)\n",
        "network = initialize_network(2, 2, 1)\n",
        " \n",
        "for layer in network:\n",
        "\tprint(layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T3wPlKp3wZZ",
        "outputId": "7e556f47-1a08-4de6-934d-604647d9580b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]},\n",
              "  {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}],\n",
              " [{'weights': [0.651592972722763, 0.7887233511355132, 0.0938595867742349]}]]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlebFxe11vpw"
      },
      "source": [
        "#2. Forward Propagate\n",
        "We can calculate an output from a neural network by propagating an input signal through each layer until the output layer outputs its values.\n",
        "\n",
        "We call this forward-propagation.\n",
        "\n",
        "It is the technique we will need to generate predictions during training that will need to be corrected, and it is the method we will need after the network is trained to make predictions on new data.\n",
        "\n",
        "We can break forward propagation down into three parts:\n",
        "\n",
        "1. Neuron Activation.\n",
        "2. Neuron Transfer.\n",
        "3. Forward Propagation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AShzxbBD3Pai"
      },
      "outputs": [],
      "source": [
        "# Calculate neuron activation for an input\n",
        "def activate(weights, inputs):\n",
        "\tactivation = weights[-1]\n",
        "\tfor i in range(len(weights)-1):\n",
        "\t\tactivation += weights[i] * inputs[i]\n",
        "\treturn activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUWww1rJYR0s",
        "outputId": "3bc40de8-bc32-4f2e-f0eb-181cba121aec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights=[1,3,2]\n",
        "inputs=[5,4,1]\n",
        " \n",
        "activate(weights,inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k3HbfNrL3Sns"
      },
      "outputs": [],
      "source": [
        "# Transfer neuron activation (using logistic regression)\n",
        "def transfer(activation):\n",
        "\treturn 1.0 / (1.0 + exp(-activation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JNg45Nba2i0P"
      },
      "outputs": [],
      "source": [
        "# Forward propagate input to a network output\n",
        "def forward_propagate(network, row):\n",
        "\tinputs = row\n",
        "\tfor layer in network:\n",
        "\t\tnew_inputs = []\n",
        "\t\tfor neuron in layer:\n",
        "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
        "\t\t\tneuron['output'] = transfer(activation)\n",
        "\t\t\tnew_inputs.append(neuron['output'])\n",
        "\t\tinputs = new_inputs\n",
        "\treturn inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHp4EQr837ZD",
        "outputId": "803f4371-1f99-4ca0-9e38-1ffbcb1643eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.7473771139195361]\n"
          ]
        }
      ],
      "source": [
        "# test forward propagation\n",
        "from math import exp \n",
        "row = [1, 0, 2,5,6]\n",
        "output = forward_propagate(network, row)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MGti_xy4yNq"
      },
      "source": [
        "# 3. Back Propagate Error\n",
        "The backpropagation algorithm is named for the way in which weights are trained.\n",
        "\n",
        "This part is broken down into two sections.\n",
        "\n",
        "1. Transfer Derivative.\n",
        "2. Error Backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vlamv2kr5IhN"
      },
      "outputs": [],
      "source": [
        "# Calculate the derivative of an neuron output\n",
        "def transfer_derivative(output):\n",
        "\treturn output * (1.0 - output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHAv3Z6fnlOu"
      },
      "source": [
        "update weighting in one epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgGYdjwO7obK",
        "outputId": "8675a855-2a2b-486b-bd1c-4a2356cd9346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'output': 0.7105668883115941, 'delta': -0.01890957872641796}, {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381], 'output': 0.6691980263750579, 'delta': -0.024637675126650903}]\n",
            "[{'weights': [0.651592972722763, 0.7887233511355132, 0.0938595867742349], 'output': 0.7473771139195361, 'delta': -0.14110820977007524}]\n"
          ]
        }
      ],
      "source": [
        " \n",
        "\n",
        "# Backpropagate error and store in neurons\n",
        "def backward_propagate_error(network, actual):\n",
        "\tfor i in reversed(range(len(network))):\n",
        "\t\tlayer = network[i]\n",
        "\t\terrors = list()\n",
        "\t\tif i != len(network)-1:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\terror = 0.0\n",
        "\t\t\t\tfor neuron in network[i + 1]:\n",
        "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
        "\t\t\t\terrors.append(error)\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\tneuron = layer[j]\n",
        "\t\t\t\terrors.append(actual[j] - neuron['output'])\n",
        "\t\tfor j in range(len(layer)):\n",
        "\t\t\tneuron = layer[j]\n",
        "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
        "\n",
        "# test backpropagation of error\n",
        "actual = [0, 1]\n",
        "backward_propagate_error(network, actual)\n",
        "for layer in network:\n",
        "\tprint(layer)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkommKDt8pML"
      },
      "source": [
        "#4. Train Network\n",
        "\n",
        "This part is broken down into two sections:\n",
        "\n",
        "1. Update Weights.\n",
        "2. Train Network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "l4_OvYD_9Eyb"
      },
      "outputs": [],
      "source": [
        "# Update network weights with error\n",
        "def update_weights(network, row, l_rate):\n",
        "\tfor i in range(len(network)):\n",
        "\t\tinputs = row[:-1]\n",
        "\t\tif i != 0:\n",
        "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "\t\tfor neuron in network[i]:\n",
        "\t\t\tfor j in range(len(inputs)):\n",
        "\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
        "\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bu8q2XVZ9X38"
      },
      "outputs": [],
      "source": [
        "# Train a network for a fixed number of epochs\n",
        "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
        "\tfor epoch in range(n_epoch):\n",
        "\t\tsum_error = 0\n",
        "\t\tfor row in train:\n",
        "\t\t\toutputs = forward_propagate(network, row)\n",
        "\t\t\texpected = [0 for i in range(n_outputs)]\n",
        "\t\t\texpected[row[-1]] = 1\n",
        "\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
        "\t\t\tbackward_propagate_error(network, expected)\n",
        "\t\t\tupdate_weights(network, row, l_rate)\n",
        "\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uEDwJwc93sS"
      },
      "source": [
        "#dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLhpcnS_95Uz",
        "outputId": "10773db1-6780-4aa5-b492-e451e06c5879"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2.7810836, 2.550537003, 0]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "dataset = [[2.7810836,2.550537003,0],\n",
        "\t[1.465489372,2.362125076,0],\n",
        "\t[3.396561688,4.400293529,0],\n",
        "\t[1.38807019,1.850220317,0],\n",
        "\t[3.06407232,3.005305973,0],\n",
        "\t[7.627531214,2.759262235,1],\n",
        "\t[5.332441248,2.088626775,1],\n",
        "\t[6.922596716,1.77106367,1],\n",
        "\t[8.675418651,-0.242068655,1],\n",
        "\t[7.673756466,3.508563011,1]]\n",
        "dataset[0] \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7hgFCX098Hu",
        "outputId": "6c2c149e-de0b-43cd-efb5-c40a312b29fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">epoch=0, lrate=0.500, error=6.523\n",
            ">epoch=1, lrate=0.500, error=5.772\n",
            ">epoch=2, lrate=0.500, error=5.361\n",
            ">epoch=3, lrate=0.500, error=5.279\n",
            ">epoch=4, lrate=0.500, error=5.276\n",
            ">epoch=5, lrate=0.500, error=5.273\n",
            ">epoch=6, lrate=0.500, error=5.255\n",
            ">epoch=7, lrate=0.500, error=5.216\n",
            ">epoch=8, lrate=0.500, error=5.140\n",
            ">epoch=9, lrate=0.500, error=4.999\n",
            ">epoch=10, lrate=0.500, error=4.779\n",
            ">epoch=11, lrate=0.500, error=4.537\n",
            ">epoch=12, lrate=0.500, error=4.286\n",
            ">epoch=13, lrate=0.500, error=4.013\n",
            ">epoch=14, lrate=0.500, error=3.721\n",
            ">epoch=15, lrate=0.500, error=3.424\n",
            ">epoch=16, lrate=0.500, error=3.131\n",
            ">epoch=17, lrate=0.500, error=2.852\n",
            ">epoch=18, lrate=0.500, error=2.592\n",
            ">epoch=19, lrate=0.500, error=2.354\n",
            "[{'weights': [0.034584833913015804, 0.6103950477885516, 0.3753934820968752], 'output': 0.9435114959695096, 'delta': -0.0009189590690010145}, {'weights': [1.1755019495382564, -1.6248769884906047, -0.165294263783588], 'output': 0.9395715816440269, 'delta': 0.011365462681896086}]\n",
            "[{'weights': [0.42252915673949987, -2.0706161682962914, 0.46108474629369], 'output': 0.26627250719228635, 'delta': -0.05202204824992197}, {'weights': [0.1291503208311031, 1.6028515758554296, -0.6470552713790686], 'output': 0.7105946580619883, 'delta': 0.05951617673373574}]\n"
          ]
        }
      ],
      "source": [
        "# Test training backprop algorithm\n",
        "n_inputs = len(dataset[0]) - 1\n",
        "n_outputs = len(set([row[-1] for row in dataset]))\n",
        "network = initialize_network(n_inputs, 2, n_outputs)\n",
        "train_network(network, dataset, 0.5, 20, n_outputs)\n",
        "for layer in network:\n",
        "\tprint(layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5eyl29Dox8l"
      },
      "outputs": [],
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLoj6zLiEJTs"
      },
      "source": [
        "# 5. Predict\n",
        "Making predictions with a trained neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "a5wfriEAEHwj"
      },
      "outputs": [],
      "source": [
        "# Make a prediction with a network\n",
        "def predict(network, row):\n",
        "\toutputs = forward_propagate(network, row)\n",
        "\treturn outputs.index(max(outputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-AoBcf9-Fn76"
      },
      "outputs": [],
      "source": [
        "# Backpropagation Algorithm With Stochastic Gradient Descent\n",
        "def back_propagation(train, test, l_rate, n_epoch, n_hidden):\n",
        "\tn_inputs = len(train[0]) - 1\n",
        "\tn_outputs = len(set([row[-1] for row in train]))\n",
        "\tnetwork = initialize_network(n_inputs, n_hidden, n_outputs)\n",
        "\ttrain_network(network, train, l_rate, n_epoch, n_outputs)\n",
        "\tpredictions = list()\n",
        "\tfor row in test:\n",
        "\t\tprediction = predict(network, row)\n",
        "\t\tpredictions.append(prediction)\n",
        "\treturn(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c87z7yRq06B",
        "outputId": "42994289-b27c-415d-8fd9-b6e6231203e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_new=[7.673756466,3.508563011]\n",
        "predict(network,x_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHgKjS01F-7J"
      },
      "source": [
        "#Apply the created FFNN on car dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "qkgKWamCGNKz",
        "outputId": "c9d5cc9c-4b96-4076-db32-43b4bbfcca9d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>15.26</th>\n",
              "      <th>14.84</th>\n",
              "      <th>0.871</th>\n",
              "      <th>5.763</th>\n",
              "      <th>3.312</th>\n",
              "      <th>2.221</th>\n",
              "      <th>5.22</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.88</td>\n",
              "      <td>14.57</td>\n",
              "      <td>0.8811</td>\n",
              "      <td>5.554</td>\n",
              "      <td>3.333</td>\n",
              "      <td>1.018</td>\n",
              "      <td>4.956</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.29</td>\n",
              "      <td>14.09</td>\n",
              "      <td>0.9050</td>\n",
              "      <td>5.291</td>\n",
              "      <td>3.337</td>\n",
              "      <td>2.699</td>\n",
              "      <td>4.825</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.84</td>\n",
              "      <td>13.94</td>\n",
              "      <td>0.8955</td>\n",
              "      <td>5.324</td>\n",
              "      <td>3.379</td>\n",
              "      <td>2.259</td>\n",
              "      <td>4.805</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.14</td>\n",
              "      <td>14.99</td>\n",
              "      <td>0.9034</td>\n",
              "      <td>5.658</td>\n",
              "      <td>3.562</td>\n",
              "      <td>1.355</td>\n",
              "      <td>5.175</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14.38</td>\n",
              "      <td>14.21</td>\n",
              "      <td>0.8951</td>\n",
              "      <td>5.386</td>\n",
              "      <td>3.312</td>\n",
              "      <td>2.462</td>\n",
              "      <td>4.956</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   15.26  14.84   0.871  5.763  3.312  2.221   5.22  1\n",
              "0  14.88  14.57  0.8811  5.554  3.333  1.018  4.956  1\n",
              "1  14.29  14.09  0.9050  5.291  3.337  2.699  4.825  1\n",
              "2  13.84  13.94  0.8955  5.324  3.379  2.259  4.805  1\n",
              "3  16.14  14.99  0.9034  5.658  3.562  1.355  5.175  1\n",
              "4  14.38  14.21  0.8951  5.386  3.312  2.462  4.956  1"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pandas import read_csv\n",
        "data=read_csv('wheat-seeds.csv')\n",
        "data.head()\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.1.1-cp310-cp310-win_amd64.whl (7.3 MB)\n",
            "     ---------------------------------------- 7.3/7.3 MB 4.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\swaraj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.22.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\swaraj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.8.0)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting joblib>=1.0.0\n",
            "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
            "Installing collected packages: threadpoolctl, joblib, scikit-learn, sklearn\n",
            "  Running setup.py install for sklearn: started\n",
            "  Running setup.py install for sklearn: finished with status 'done'\n",
            "Successfully installed joblib-1.1.0 scikit-learn-1.1.1 sklearn-0.0 threadpoolctl-3.1.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\Swaraj\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "%pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "iApjF5xHHA9v",
        "outputId": "c416fc49-24e5-4b3a-e39b-e2d8411eb77d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>15.26</th>\n",
              "      <th>14.84</th>\n",
              "      <th>0.871</th>\n",
              "      <th>5.763</th>\n",
              "      <th>3.312</th>\n",
              "      <th>2.221</th>\n",
              "      <th>5.22</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>12.55</td>\n",
              "      <td>13.57</td>\n",
              "      <td>0.8558</td>\n",
              "      <td>5.333</td>\n",
              "      <td>2.968</td>\n",
              "      <td>4.419</td>\n",
              "      <td>5.176</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>18.95</td>\n",
              "      <td>16.42</td>\n",
              "      <td>0.8829</td>\n",
              "      <td>6.248</td>\n",
              "      <td>3.755</td>\n",
              "      <td>3.368</td>\n",
              "      <td>6.148</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>16.84</td>\n",
              "      <td>15.67</td>\n",
              "      <td>0.8623</td>\n",
              "      <td>5.998</td>\n",
              "      <td>3.484</td>\n",
              "      <td>4.675</td>\n",
              "      <td>5.877</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>18.14</td>\n",
              "      <td>16.12</td>\n",
              "      <td>0.8772</td>\n",
              "      <td>6.059</td>\n",
              "      <td>3.563</td>\n",
              "      <td>3.619</td>\n",
              "      <td>6.011</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>17.99</td>\n",
              "      <td>15.86</td>\n",
              "      <td>0.8992</td>\n",
              "      <td>5.890</td>\n",
              "      <td>3.694</td>\n",
              "      <td>2.068</td>\n",
              "      <td>5.837</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     15.26  14.84   0.871  5.763  3.312  2.221   5.22  1\n",
              "162  12.55  13.57  0.8558  5.333  2.968  4.419  5.176  3\n",
              "103  18.95  16.42  0.8829  6.248  3.755  3.368  6.148  2\n",
              "70   16.84  15.67  0.8623  5.998  3.484  4.675  5.877  2\n",
              "120  18.14  16.12  0.8772  6.059  3.563  3.619  6.011  2\n",
              "100  17.99  15.86  0.8992  5.890  3.694  2.068  5.837  2"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        " \n",
        "X_train,X_test =train_test_split(data,test_size=0.1)\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14Gzb4OgHj7N",
        "outputId": "ca3a4071-f982-4f9b-86ec-0d68581a78da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores: [95.23809523809523, 92.85714285714286, 97.61904761904762, 92.85714285714286, 90.47619047619048]\n",
            "Mean Accuracy: 93.810%\n"
          ]
        }
      ],
      "source": [
        "# Backprop on the Seeds Dataset\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from random import random\n",
        "from csv import reader\n",
        "from math import exp\n",
        "\n",
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "\tdataset = list()\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\tcsv_reader = reader(file)\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\tif not row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdataset.append(row)\n",
        "\treturn dataset\n",
        "\n",
        "# Convert string column to float\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column].strip())\n",
        "\n",
        "# Convert string column to integer\n",
        "def str_column_to_int(dataset, column):\n",
        "\tclass_values = [row[column] for row in dataset]\n",
        "\tunique = set(class_values)\n",
        "\tlookup = dict()\n",
        "\tfor i, value in enumerate(unique):\n",
        "\t\tlookup[value] = i\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = lookup[row[column]]\n",
        "\treturn lookup\n",
        "\n",
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "\tminmax = list()\n",
        "\tstats = [[min(column), max(column)] for column in zip(*dataset)]\n",
        "\treturn stats\n",
        "\n",
        "# Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "\tfor row in dataset:\n",
        "\t\tfor i in range(len(row)-1):\n",
        "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
        "\n",
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "\tdataset_split = list()\n",
        "\tdataset_copy = list(dataset)\n",
        "\tfold_size = int(len(dataset) / n_folds)\n",
        "\tfor i in range(n_folds):\n",
        "\t\tfold = list()\n",
        "\t\twhile len(fold) < fold_size:\n",
        "\t\t\tindex = randrange(len(dataset_copy))\n",
        "\t\t\tfold.append(dataset_copy.pop(index))\n",
        "\t\tdataset_split.append(fold)\n",
        "\treturn dataset_split\n",
        "\n",
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "\tcorrect = 0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tif actual[i] == predicted[i]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn correct / float(len(actual)) * 100.0\n",
        "\n",
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "\tfolds = cross_validation_split(dataset, n_folds)\n",
        "\tscores = list()\n",
        "\tfor fold in folds:\n",
        "\t\ttrain_set = list(folds)\n",
        "\t\ttrain_set.remove(fold)\n",
        "\t\ttrain_set = sum(train_set, [])\n",
        "\t\ttest_set = list()\n",
        "\t\tfor row in fold:\n",
        "\t\t\trow_copy = list(row)\n",
        "\t\t\ttest_set.append(row_copy)\n",
        "\t\t\trow_copy[-1] = None\n",
        "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
        "\t\tactual = [row[-1] for row in fold]\n",
        "\t\taccuracy = accuracy_metric(actual, predicted)\n",
        "\t\tscores.append(accuracy)\n",
        "\treturn scores\n",
        "\n",
        "# Calculate neuron activation for an input\n",
        "def activate(weights, inputs):\n",
        "\tactivation = weights[-1]\n",
        "\tfor i in range(len(weights)-1):\n",
        "\t\tactivation += weights[i] * inputs[i]\n",
        "\treturn activation\n",
        "\n",
        "# Transfer neuron activation\n",
        "def transfer(activation):\n",
        "\treturn 1.0 / (1.0 + exp(-activation))\n",
        "\n",
        "# Forward propagate input to a network output\n",
        "def forward_propagate(network, row):\n",
        "\tinputs = row\n",
        "\tfor layer in network:\n",
        "\t\tnew_inputs = []\n",
        "\t\tfor neuron in layer:\n",
        "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
        "\t\t\tneuron['output'] = transfer(activation)\n",
        "\t\t\tnew_inputs.append(neuron['output'])\n",
        "\t\tinputs = new_inputs\n",
        "\treturn inputs\n",
        "\n",
        "# Calculate the derivative of an neuron output\n",
        "def transfer_derivative(output):\n",
        "\treturn output * (1.0 - output)\n",
        "\n",
        "# Backpropagate error and store in neurons\n",
        "def backward_propagate_error(network, expected):\n",
        "\tfor i in reversed(range(len(network))):\n",
        "\t\tlayer = network[i]\n",
        "\t\terrors = list()\n",
        "\t\tif i != len(network)-1:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\terror = 0.0\n",
        "\t\t\t\tfor neuron in network[i + 1]:\n",
        "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
        "\t\t\t\terrors.append(error)\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\tneuron = layer[j]\n",
        "\t\t\t\terrors.append(expected[j] - neuron['output'])\n",
        "\t\tfor j in range(len(layer)):\n",
        "\t\t\tneuron = layer[j]\n",
        "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
        "\n",
        "# Update network weights with error\n",
        "def update_weights(network, row, l_rate):\n",
        "\tfor i in range(len(network)):\n",
        "\t\tinputs = row[:-1]\n",
        "\t\tif i != 0:\n",
        "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "\t\tfor neuron in network[i]:\n",
        "\t\t\tfor j in range(len(inputs)):\n",
        "\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
        "\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']\n",
        "\n",
        "# Train a network for a fixed number of epochs\n",
        "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
        "\tfor epoch in range(n_epoch):\n",
        "\t\tfor row in train:\n",
        "\t\t\toutputs = forward_propagate(network, row)\n",
        "\t\t\texpected = [0 for i in range(n_outputs)]\n",
        "\t\t\texpected[row[-1]] = 1\n",
        "\t\t\tbackward_propagate_error(network, expected)\n",
        "\t\t\tupdate_weights(network, row, l_rate)\n",
        "\n",
        "# Initialize a network\n",
        "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
        "\tnetwork = list()\n",
        "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
        "\tnetwork.append(hidden_layer)\n",
        "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
        "\tnetwork.append(output_layer)\n",
        "\treturn network\n",
        "\n",
        "# Make a prediction with a network\n",
        "def predict(network, row):\n",
        "\toutputs = forward_propagate(network, row)\n",
        "\treturn outputs.index(max(outputs))\n",
        "\n",
        "# Backpropagation Algorithm With Stochastic Gradient Descent\n",
        "def back_propagation(train, test, l_rate, n_epoch, n_hidden):\n",
        "\tn_inputs = len(train[0]) - 1\n",
        "\tn_outputs = len(set([row[-1] for row in train]))\n",
        "\tnetwork = initialize_network(n_inputs, n_hidden, n_outputs)\n",
        "\ttrain_network(network, train, l_rate, n_epoch, n_outputs)\n",
        "\tpredictions = list()\n",
        "\tfor row in test:\n",
        "\t\tprediction = predict(network, row)\n",
        "\t\tpredictions.append(prediction)\n",
        "\treturn(predictions)\n",
        "\n",
        "# Test Backprop on Seeds dataset\n",
        "seed(1)\n",
        "# load and prepare data\n",
        "filename = 'wheat-seeds.csv'\n",
        "dataset = load_csv(filename)\n",
        "for i in range(len(dataset[0])-1):\n",
        "\tstr_column_to_float(dataset, i)\n",
        "# convert class column to integers\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\n",
        "# normalize input variables\n",
        "minmax = dataset_minmax(dataset)\n",
        "normalize_dataset(dataset, minmax)\n",
        "# evaluate algorithm\n",
        "n_folds = 5\n",
        "l_rate = 0.3\n",
        "n_epoch = 500\n",
        "n_hidden = 5\n",
        "scores = evaluate_algorithm(dataset, back_propagation, n_folds, l_rate, n_epoch, n_hidden)\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBnxSVbkM97q"
      },
      "outputs": [],
      "source": [
        " "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "FFNN.sas.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8742b902b0ea51623832f28828365e7f785ea88fdfcb7a3f809c86ca116dfdcb"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
